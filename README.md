# eduagents3.0

**Transform static educational assessments into dynamic, multidimensional simulations.**

eduagents3.0 is an intelligent assessment platform that helps teachers author better assignments by analyzing them through the lens of diverse student personas. Using deterministic simulation and math-driven diagnostics, it produces actionable insights and intelligent rewrites.

## ğŸ¯ Core Philosophy

- **Problem-centric tagging**: Every problem is decomposed with Bloom's taxonomy, linguistic complexity, and novelty scores
- **Learner profiling**: Students represented as personas with accessibility overlays and trait profiles  
- **Simulation-driven feedback**: Rich interactions model realistic student performance
- **Iterative refinement**: Intelligent rewriting based on simulation output

---

## ğŸ—ï¸ Architecture: Five-Phase Pipeline

### Phase 1: Document Ingestion â†’ Asteroids
Parse PDF, Word, or text files into discrete problems with pedagogical metadata:
- **Bloom Level**: Remember | Understand | Apply | Analyze | Evaluate | Create
- **Linguistic Complexity**: 0.0â€“1.0 (Flesch-Kincaid based)
- **Novelty Score**: 0.0â€“1.0 (cosine similarity to previous problems)
- **Multipart Detection**: Whether problem has subparts
- **Estimated Time**: Seconds to complete

**Files**: `src/agents/shared/parseFiles.ts`, `src/agents/analysis/analyzeTags.ts`

### Phase 2: Student Creation â†’ Astronauts  
Define diverse learner personas with accessibility needs:
- **ProfileTraits**: ReadingLevel, MathFluency, AttentionSpan, Confidence (0.0â€“1.0 each)
- **Overlays**: ADHD, dyslexia, fatigue_sensitivity, visual-learner, etc.
- **NarrativeTags**: Learning characteristics (focused, creative, analytical, etc.)

**Files**: `src/agents/simulation/accessibilityProfiles.ts`, `src/types/simulation.ts`

### Phase 3: Simulation Engine â†’ StudentFeedback
Simulate each (Student, Problem) pair and generate realistic performance metrics:
- **PerceivedSuccess**: 0.0â€“1.0 based on student traits vs. problem difficulty
- **TimeOnTask**: Seconds estimated from problem attributes and student speed
- **ConfusionSignals**: Integer count of struggle points
- **FatigueIndex**: 0.0â€“1.0 cumulative from prior problems
- **EngagementScore**: 0.0â€“1.0 inferred from novelty and success

**Files**: `src/agents/simulation/simulateStudents.ts`, `src/types/simulation.ts`

### Phase 4: Philosopher Diagnostic Engine â†’ Ranked Feedback
The **Philosopher v13** engine (newly integrated) analyzes assignments across 20 synthetic student personas:

1. **Generate Synthetic Students**: 20 personas with diverse profiles and overlays
2. **Simulate Performance**: Run each student through all problems
3. **Aggregate Metrics**: Compute mean (Î¼) and standard deviation (Ïƒ) for each problem
4. **Derive Thresholds**: Î¼ Â± Ïƒ defines "elevated" and "severe" performance gaps
5. **Detect Clusters**: Find adjacent problems that trigger the same issues (confusion, fatigue, failure, timing, complexity mismatch)
6. **Compute Severity**: Score 0â€“1 using formula: `magnitude Ã— cluster_weight Ã— impact_weight`
7. **Generate Ranked Feedback**: Sort issues by severity; highest first
8. **Render Visualizations**: 6 SVG charts (pacing, confusion, engagement, bloom, fatigue, success)

**Features**:
- âœ… Fully deterministic (same input = same output)
- âœ… Zero external dependencies
- âœ… Math-driven thresholds (not hardcoded)
- âœ… Identifies problem clusters (not just individual issues)
- âœ… Severity scoring for prioritization
- âœ… Evidence-based recommendations
- âœ… 6 production-grade visualizations

**Files**: `src/agents/analysis/philosopherEngine.ts`, `src/agents/analysis/philosophers.ts`

### Phase 5: Rewriter â†’ Adaptive Assignment
Generate improved version based on Philosopher feedback:
- Adjust Bloom levels (e.g., "Remember" â†’ "Understand")
- Reduce linguistic complexity
- Break up multipart questions
- Improve novelty balance
- Generate accessibility variants

**Files**: `src/agents/rewrite/rewriteAssignment.ts`

---

## ğŸš€ Key Features

### Teacher Workflow
1. **Upload Assignment**: PDF, Word, or paste text
2. **Analyze Problems**: System extracts 5â€“30 discrete problems with Bloom tagging
3. **Review Metadata**: Edit grade level, subject, and problem details
4. **Simulate Students**: Run 20 personas through all problems
5. **Get Philosopher Feedback**: Ranked recommendations + 6 visualizations
6. **Accept or Reject**: AI rewrites based on feedback, or export as-is

### Intelligent Analytics
- **Completion Rate**: % of student personas expected to finish on-time
- **Bloom Coverage**: Distribution across cognitive levels
- **At-Risk Detection**: Which personas will struggle
- **Novelty Balance**: Problem repetition analysis
- **Fatigue Prediction**: Cumulative cognitive load by problem

### Accessibility Support
- **ADHD-Friendly**: Shorter tasks, frequent checkpoints
- **Dyslexia-Optimized**: Sans-serif fonts, high contrast
- **Fatigue Sensitivity**: Tracked cumulative load
- **Visual Learner**: Recommended diagrams/charts
- **Custom Overlays**: Define your own accessibility needs

---

## ğŸ’» Tech Stack

**Frontend**:
- React 19 with TypeScript 5.6
- Vite 5 (build tool)
- Recharts (visualizations)
- Supabase Auth (user management)

**Document Processing**:
- pdfjs-dist (PDF parsing)
- mammoth (Word parsing)
- jsPDF (PDF generation)

**Storage**:
- Supabase (PostgreSQL backend)

**Testing**:
- Vitest (unit tests)
- @testing-library/react (component tests)

---

## ğŸ”’ AI API Enforcement & Production Safety

This application implements **strict fail-fast AI enforcement** with zero graceful degradation. All five phases require real Google Generative AI (Gemini) to function.

### 5-Step Enforcement Architecture

**Step 1: Remove Silent Fallbacks**
- All mock response defaults eliminated
- Empty AI responses throw explicit errors
- No silent failure modes

**Step 2: Enforce Real AI at Initialization**
- `VITE_GOOGLE_API_KEY` required before app boots
- Application prevents rendering without valid API key
- Explicit error message on startup

**Step 3: Force Failure On Empty Responses**
- All AI calls validate non-empty response text
- Empty responses throw detailed error explaining failure
- No template/default fallbacks

**Step 4: Central AI Wrapper Function**
- Single `callAI()` export from `src/config/aiConfig.ts`
- All API calls pass through this wrapper
- Unified validation and error handling
- No direct Gemini API calls allowed

**Step 5: Production Build Guards**
- Mock AI strictly development-only
- Production/preview builds require real API key
- `getMockAIService()` throws in non-dev environments
- Development mock requires explicit `VITE_ENABLE_MOCK_AI=true` flag

### Environment Variables

**Required (Production)**:
```bash
VITE_GOOGLE_API_KEY=AIzaXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
```
Obtained from [Google AI Studio](https://aistudio.google.com/app/apikey)

**Optional (Development Only)**:
```bash
# Enable mock AI in development (requires flag + isDev check)
VITE_ENABLE_MOCK_AI=true
```

### Production vs Development

| Scenario | Allowed | Behavior |
|----------|---------|----------|
| Production build without `VITE_GOOGLE_API_KEY` | âŒ NO | Throws error before app loads |
| Preview/staging without API key | âŒ NO | Throws error during initialization |
| Development without API key, without flag | âŒ NO | Real AI unavailable error |
| Development with `VITE_ENABLE_MOCK_AI=true` | âœ… YES | Uses mock AI for testing |
| Any build with `VITE_GOOGLE_API_KEY` | âœ… YES | Uses real Gemini AI (production-safe) |

### Safety Guarantees

- âœ… **No bypasses**: All AI calls routed through `callAI()` wrapper
- âœ… **No fallbacks**: Every AI failure throws explicit error
- âœ… **Type-safe**: Full TypeScript validation end-to-end
- âœ… **Production-locked**: Mock AI impossible in non-dev builds
- âœ… **Deterministic**: Same input always produces same output

### File References

- **Central wrapper**: [src/config/aiConfig.ts](src/config/aiConfig.ts) â€“ `callAI()` function (line ~290)
- **Service manager**: [src/agents/api/aiService.ts](src/agents/api/aiService.ts) â€“ `AIServiceManager` singleton
- **App initialization**: [src/index.tsx](src/index.tsx) â€“ API key check (line 12)
- **Configuration**: [src/config/aiConfig.ts](src/config/aiConfig.ts) â€“ `getAIConfig()`, `useRealAI()`, `getAIService()`

---

## ğŸ¯ Getting Started

### Prerequisites
- Node.js 18+
- npm 9+
- **Google API Key** (for production or real AI testing)

### Installation

```bash
# Clone the repository
git clone https://github.com/andyMattick/eduagents3.0.git
cd eduagents3.0

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env.local

# âš ï¸  IMPORTANT: Add your Google API key (required for all functionality)
# Edit .env.local and add:
#   VITE_GOOGLE_API_KEY=AIzaXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
# Get key from: https://aistudio.google.com/app/apikey

# Optional: For development-only mock AI testing
#   VITE_ENABLE_MOCK_AI=true

# Start development server
npm run dev
```

Visit `http://localhost:5173` in your browser.

**Note**: Without `VITE_GOOGLE_API_KEY`, the app will not load. A clear error message will appear explaining the requirement.

### Build for Production

```bash
npm run build        # Compile TypeScript and bundle
npm run preview      # Preview production build locally
npm test             # Run test suite
```

**Production Deployment Requirements**:
- âœ… `VITE_GOOGLE_API_KEY` environment variable must be set
- âœ… Application will fail to initialize without valid API key
- âœ… No fallback or mock AI in production builds

---

## ğŸ“‚ Project Structure

```
src/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ analysis/              # Bloom classification, tag extraction, Philosopher
â”‚   â”‚   â”œâ”€â”€ analyzeTags.ts     # Extract pedagogical tags
â”‚   â”‚   â””â”€â”€ philosopherEngine.ts  # v13 diagnostic engine (820 lines)
â”‚   â”œâ”€â”€ simulation/            # Student personas and feedback generation
â”‚   â”‚   â”œâ”€â”€ simulateStudents.ts
â”‚   â”‚   â””â”€â”€ accessibilityProfiles.ts
â”‚   â”œâ”€â”€ rewrite/              # Assignment rewriting with AI
â”‚   â”œâ”€â”€ shared/               # Document parsing, metadata inference
â”‚   â””â”€â”€ pipelineIntegration.ts # Orchestration
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Pipeline/             # Main 5-step UI workflow
â”‚   â”‚   â”œâ”€â”€ PipelineShell.tsx  # Router and state management
â”‚   â”‚   â”œâ”€â”€ PhilosopherReview.tsx  # Feedback display (v13)
â”‚   â”‚   â””â”€â”€ PhilosophersVisualsPanel.tsx  # 6 charts
â”‚   â”œâ”€â”€ Auth/                 # Login/signup
â”‚   â””â”€â”€ Admin/                # Teacher dashboard
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ usePipeline.ts        # State management for workflow
â”œâ”€â”€ types/
â”‚   â”œâ”€â”€ pipeline.ts           # State types
â”‚   â”œâ”€â”€ simulation.ts         # Asteroid/Astronaut types
â”‚   â””â”€â”€ universalPayloads.ts  # UniversalProblem types
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ authService.ts        # Supabase Auth
â”‚   â”œâ”€â”€ teacherSystemService.ts  # Database operations
â”‚   â””â”€â”€ teacherNotesService.ts
â””â”€â”€ lib/
    â””â”€â”€ supabaseClient.ts     # Supabase client initialization
```

---

## ğŸ“Š Data Models

### Asteroid (Problem)
```typescript
{
  ProblemId: string,
  ProblemText: string,
  BloomLevel: "Remember" | "Understand" | "Apply" | "Analyze" | "Evaluate" | "Create",
  LinguisticComplexity: 0.0â€“1.0,
  NoveltyScore: 0.0â€“1.0,
  MultiPart: boolean,
  EstimatedTimeSeconds: number,
  // ... other metadata
}
```

### Astronaut (Student Persona)
```typescript
{
  StudentId: string,
  PersonaName: string,
  Overlays: string[],  // e.g., ["adhd", "dyslexic"]
  ProfileTraits: {
    ReadingLevel: 0.0â€“1.0,
    MathFluency: 0.0â€“1.0,
    AttentionSpan: 0.0â€“1.0,
    Confidence: 0.0â€“1.0
  }
}
```

### Teacher Feedback (from Philosopher)
```typescript
{
  rankedFeedback: {
    title: string,
    description: string,
    priority: "high" | "medium" | "low",
    affectedProblems: string[],
    recommendation: string,
    estimatedImpact: "high" | "medium" | "low",
    category: string,
    severity: 0.0â€“1.0
  }[],
  visualizations: {
    pacingChart: string,     // SVG
    confusionHeatmap: string,
    engagementTrend: string,
    bloomMismatch: string,
    fatigueCurve: string,
    successDistribution: string
  }
}
```

---

## ğŸ§™ Philosopher v13 Deep Dive

The Philosopher engine is the heart of the analysis system. It produces deterministic, math-driven feedback:

### The 8-Step Process

1. **generateSyntheticStudents(20)** â€“ Create personas covering a spectrum of learning profiles
2. **simulatePerformance()** â€“ Run each student through all problems
3. **aggregateMetrics()** â€“ Compute success rate, time, confusion for each problem
4. **deriveThresholds()** â€“ Calculate Î¼ Â± Ïƒ for each metric dynamically
5. **detectClusters()** â€“ Find adjacent problems with elevated metrics (5 cluster types)
6. **computeSeverity()** â€“ Score 0â€“1: `magnitude Ã— cluster_weight Ã— impact_weight`
7. **generateRankedFeedback()** â€“ Sort by severity; produce evidence + actions
8. **generateVisualizations()** â€“ Render 6 SVG charts

### Key Guarantees

- **Determinism**: Same input â†’ same output, no randomness
- **Type Safety**: Full TypeScript, no `any` types
- **Performance**: <2 seconds for typical assignments (5â€“30 problems)
- **Fallbacks**: Graceful error handling; never crashes UI
- **Immutability**: No mutations of input problems

### 6 Visualizations

1. **Pacing Chart**: Time distribution across problems
2. **Confusion Heatmap**: Problem Ã— persona struggle map
3. **Engagement Trend**: How engagement evolves through assignment
4. **Bloom Mismatch**: Cognitive load vs. actual Bloom levels
5. **Fatigue Curve**: Cumulative student fatigue buildup
6. **Success Distribution**: Persona success rates across problems

---

## ğŸ”„ Integration Status

### âœ… Completed
- Phase 1: Document ingestion (PDF, Word, text)
- Phase 2: Astronaut creation with overlays
- Phase 3: Simulation engine with StudentFeedback
- **Phase 4: Philosopher v13 diagnostic engine** â† NEW (Feb 13, 2026)
- Phase 5: Rewriter for adaptive assignments
- Authentication (Supabase)
- Problem banking and persistence
- Teacher notes and annotations

### â³ In Development
- Advanced analytics dashboard
- Custom learner profile creation UI
- Export formats (PDF, Word, SCORM)
- LMS integrations

---

## ğŸ§ª Testing

### Run Tests
```bash
npm test                 # Run all tests
npm test -- --watch     # Watch mode
npm test -- --ui        # UI for Vitest
```

### Manual Testing Checklist
1. Upload a 5-problem assignment
2. Verify Philosopher runs and generates feedback
3. Check that 6 visualizations render
4. Test Accept â†’ Rewrite flow
5. Test Reject â†’ Export flow

---

## ğŸ“‹ API Contracts

### Phase 3: Simulation
**Input** (SimulateStudentsPayload):
- `assignmentText`: Raw assignment content
- `asteroids?`: Structured problems (optional)
- `assignmentMetadata`: Grade level, subject
- `selectedStudentTags?`: Filter personas

**Output** (StudentFeedback[]):
```typescript
{
  studentPersona: string,
  timeToCompleteMinutes: number,
  understoodConcepts: string[],
  struggledWith: string[],
  atRiskProfile?: boolean
}
```

### Phase 4: Philosopher Diagnostic
**Input** (PhilosopherPayload):
```typescript
{
  problems: UniversalProblem[],
  generationContext: {
    subject: string,
    gradeBand: string,
    timeTargetMinutes: number
  }
}
```

**Output** (TeacherFeedbackOptions):
```typescript
{
  rankedFeedback: FeedbackItem[],
  visualizations: {
    [key: string]: string  // SVG strings
  },
  metadata: {
    clusterCount: number,
    predictedTotalTime: number,
    overallRiskLevel: "low" | "medium" | "high"
  }
}
```

---

## ğŸš€ Deployment

### Development
```bash
npm run dev        # Hot-reload dev server on port 5173
```

### Production

```bash
# Build the application
npm run build      # TypeScript compilation + Vite bundling

# Set environment variables in your deployment platform
VITE_GOOGLE_API_KEY=AIzaXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# Serve the built app
npm run preview    # Local preview
# OR deploy to your hosting platform (Vercel, Netlify, etc.)
```

**Required Steps**:
1. Generate Google API key from [AI Studio](https://aistudio.google.com/app/apikey)
2. Add `VITE_GOOGLE_API_KEY` to production environment variables
3. Ensure `NODE_ENV=production` is set
4. Deploy to hosting platform
5. Verify app loads without API key errors

**Staging Flow**:
1. Deploy to `staging` branch with valid API key
2. Test for 24 hours
3. Verify no AI failures or timeout issues
4. Promote to `main` branch for production

**Troubleshooting**:
- If app won't load: Check browser console for API key error message
- If AI calls fail: Verify API key is valid and has proper permissions
- If preview fails: Ensure `VITE_GOOGLE_API_KEY` is set in local `.env.local`

---

## ğŸ“š Documentation

- **[PHILOSOPHER_V13_QUICKSTART.md](./PHILOSOPHER_V13_QUICKSTART.md)** â€“ 30-second quick reference
- **[DEPLOYMENT_CHECKLIST_PHILOSOPHER_V13.md](./DEPLOYMENT_CHECKLIST_PHILOSOPHER_V13.md)** â€“ Pre/post deployment steps
- **[INTEGRATION_DEPLOYMENT_SUMMARY.md](./INTEGRATION_DEPLOYMENT_SUMMARY.md)** â€“ Integration summary
- **[.github/copilot-instructions.md](./.github/copilot-instructions.md)** â€“ Full architecture guide

---

## ğŸ¤ Contributing

1. **Create a branch** from `dev`
2. **Make changes** with TypeScript type safety
3. **Test locally** with `npm test` and `npm run build`
4. **Submit PR** to `dev` for review
5. **Merge to `main`** for production deployment

---

## ğŸ“ Support & Troubleshooting

### Common Issues

**"VITE_GOOGLE_API_KEY missing. Real AI is required..."**
- **Cause**: API key not set in environment
- **Solution**: Add `VITE_GOOGLE_API_KEY` to `.env.local` (development) or deployment settings (production)
- **Where to get key**: https://aistudio.google.com/app/apikey

**"Real AI is not available. VITE_GOOGLE_API_KEY must be set."**
- **Cause**: App initialized without API key
- **Solution**: Set `VITE_GOOGLE_API_KEY` before starting the server

**"Mock AI is disabled in production/preview"**
- **Cause**: Attempted to use mock AI outside of development mode
- **Solution**: Cannot use mock in production. Provide real API key instead.

**"Mock AI is disabled. Set VITE_ENABLE_MOCK_AI=true in development..."**
- **Cause**: Attempted to use mock AI in development without explicit flag
- **Solution**: In `.env.local`, add `VITE_ENABLE_MOCK_AI=true`

### General Support

For questions or issues:
1. Check this README for environment setup
2. Review [.github/copilot-instructions.md](./.github/copilot-instructions.md) for architecture
3. Check [PHILOSOPHER_V13_QUICKSTART.md](./PHILOSOPHER_V13_QUICKSTART.md) for feature specifics
4. Verify build with `npm run build`
5. Check browser console (F12) for detailed error messages

---

## ğŸ“„ License

Private proprietary software. All rights reserved.

---

**Last Updated**: February 13, 2026  
**Current Version**: 1.0.0-hardened (Philosopher v13 + AI Enforcement)  
**Status**: Production-ready âœ…  

### Recent Changes (Feb 13, 2026)
- âœ… **Step 1**: Removed all silent fallbacks; explicit error throws on AI failure
- âœ… **Step 2**: Enforced real AI at initialization; mandatory `VITE_GOOGLE_API_KEY`
- âœ… **Step 3**: Forced empty response validation; no template defaults
- âœ… **Step 4**: Created central `callAI()` wrapper; consolidated all API calls
- âœ… **Step 5**: Production build guards; mock AI only with dev flag
- âœ… **Documentation**: Updated README with environment setup and troubleshooting